# MachineLearning

 **Содержание:**
 - [Обучение с учителем и без учителя](#item-1)
 - [Задачи классификации](#item-2)
 - [Регрессия (в контексте нейронок)](#item-3)
 - [Расхождение Кульбака-Лейбмана (какая-то фигня)](#item-4)
 - [Критерии оптимизации](#item-5)
 - [Способы оптимизации функций (градиентный спуск)](#item-6)
   - [Простыми словами](#item-7)
   - [Научно](#item-8)
 - [Функции активации](#item-9)
 - [Метрики качества в заданных классификациях](#item-10)

<a id="item-1"></a>
## 1. Обучение с учителем и без учителя 

### Обучение с учителем
Обучение с учителем предполагает, что для каждого примера из обучающего набора данных известен правильный ответ (метка). Целью является построение модели, которая научится предсказывать метки для новых, ранее не виденных данных.

***Примеры задач:***

* Классификация (например, определение спама)
* Регрессия (например, прогнозирование цен на дома)

**Процесс обучения:**

* Выбор модели: это может быть линейная модель, дерево решений, нейронная сеть и т.д.
* Обучение модели: на основе обучающих данных (фичи и метки) модель настраивает свои параметры так, чтобы минимизировать ошибку между предсказанными и реальными метками.
* Валидация и тестирование: проверка качества модели на отдельном наборе данных для оценки ее способности к обобщению на новых данных.

### Обучение без учителя
В задачах обучения без учителя правильные ответы (метки) неизвестны, и целью является обнаружение взаимосвязей и структур в данных на основе входных признаков.

***Примеры задач:***

* Кластеризация (например, сегментация покупателей по поведению)
* Уменьшение размерности (например, PCA для упрощения данных без значительной потери информации).
  *PCA (Метод главных компонент) — один из основных способов уменьшить размерность данных, потеряв наименьшее количество информации.*
* Выявление аномалий (например, обнаружение мошенничества)

**Процесс обучения:**

* Выбор модели: в зависимости от поставленной задачи это может быть алгоритм кластеризации как K-means, алгоритм для снижения размерности как PCA, или другие.
* Обучение модели: модель исследует структуру в данных, чтобы выделить кластеры, главные компоненты или аномалии без использования меток.
* Интерпретация полученных результатов: важная часть процесса, поскольку отсутствие явных меток зачастую делает результаты менее очевидными.


### Отличия между обучением с учителем и без учителя
* Наличие меток: В обучении с учителем каждый пример в обучающем наборе помечен правильным ответом. В обучении без учителя метки отсутствуют.
* Задачи и цели: Обучение с учителем часто направлено на предсказание конкретных результатов (классификация, регрессия), тогда как обучение без учителя фокусируется на исследовании структур данных (кластеризация, уменьшение размерности).
* Оценка результатов: В обучении с учителем четкость оценки облегчается наличием реальных меток, по которым можно судить о качестве модели. В обучении без учителя оценка качества может быть менее прямолинейной из-за отсутствия явных критериев успеха.

<a id="item-2"></a>
## 2. Задачи классификации

### Классификация
Задачи классификации в контексте машинного обучения представляют собой тип задач обучения с учителем, целью которых является предсказание категориальных меток для данных. В этих задачах, данные или объекты необходимо классифицировать по определённым классам на основе их характеристик или признаков.

#### Основные понятия
* Классы: Предопределённые группы или категории, к которым должны быть отнесены примеры данных. Например, в задаче по определению спама классы могут быть "спам" и "не спам".
* Признаки (фичи): Характеристики или атрибуты данных, на основе которых модель обучается делать предсказания. Например, в текстовых данных это могут быть частоты встречаемости слов.
* Метки: Конкретные значения классов, присвоенные каждому объекту тренировочных данных. В процессе обучения использование меток позволяет модели "учиться" правильной классификации.

#### Типы задач классификации
* Бинарная классификация: Когда имеются всего два класса. Пример – определение, является ли электронное письмо спамом.
* Многоклассовая классификация (мультиклассовая классификация): Когда объекты классифицируются на более чем два класса. Пример – классификация новостных статей по тематикам.
* Многокатегорийная классификация (мультилейбл классификация): Когда объект может одновременно принадлежать к нескольким классам. Пример – классификация изображения, на котором изображены несколько объектов.

#### Процесс обучения модели классификации
* Предобработка данных: Включает в себя нормализацию признаков, заполнение пропущенных значений, кодирование категориальных переменных и т.д.
* Выбор модели: В зависимости от задачи и данных это может быть логистическая регрессия, дерево решений, случайный лес, градиентный бустинг, нейронная сеть и т.д.
* Обучение модели: В процессе обучения модель "изучает" взаимосвязь между признаками и метками на тренировочном наборе данных.
* Оценка модели: Проверка качества классификации модели на валидационном и тестовом наборах данных. Используются метрики, как точность (accuracy), точность (precision), полнота (recall), F-мера и другие.

#### Метрики оценки
* Точность (Accuracy): Общая доля правильно классифицированных случаев из всех случаев.
* Точность (Precision): Доля правильно классифицированных положительных случаев из всех случаев, классифицированных как положительные.
* Полнота (Recall): Доля правильно классифицированных положительных случаев из всех реальных положительных случаев.
* F-мера (F1-Score): Среднее гармоническое точности и полноты. Используется, когда требуется сбалансировать между точностью и полнотой.

<a id="item-3"></a>
## 3. Регрессия (в контексте нейронок) 

Задачи регрессии в контексте машинного обучения относятся к типу задач обучения с учителем, где целью является предсказание непрерывной величины, основываясь на одном или нескольких входных признаках. Это отличается от задач классификации, где предсказываемая величина является категориальной.

### Понятие регрессии
Регрессия заключается в нахождении зависимости между набором независимых переменных (признаками) и зависимой переменной (целевым признаком). Задача регрессии сводится к построению модели регрессии, которая на основе предоставляемых данных способна с максимальной точностью предсказывать значение зависимой переменной.

### Типы задач регрессии
* Линейная регрессия: Предполагает линейную связь между входными переменными и целевой переменной. В простейшем случае одной переменной это может быть уравнение вида (y = mx + b), где (y) – целевая переменная, (x) – входная переменная, (m) и (b) – параметры модели, которые необходимо определить.
* Множественная регрессия: Расширение линейной регрессии для случаев, когда для предсказания используется несколько входных переменных.
* Полиномиальная регрессия: В случае, когда отношение между входными переменными и выходной переменной лучше описывается полиномом, высшей степени.
* Регрессия с регуляризацией: Применяется для избежания переобучения модели путем добавления штрафа за слишком высокие значения параметров модели (например, Lasso или Ridge регрессия).
### Процесс обучения модели регрессии
* Сбор и подготовка данных: Очистка, нормализация, а также выбор и создание соответствующих признаков.
* Выбор модели: Определение, какая модель регрессии лучше всего подходит для конкретной задачи.
* Обучение модели: Использование тренировочного набора данных для подгонки модели, т.е. определения её параметров.
* Оценка модели: Проверка качества модели с использованием тестового набора данных и соответствующих метрик (например, среднеквадратичная ошибка (MSE), коэффициент детерминации (R^2)).
### Метрики оценки задач регрессии
* Среднеквадратичная ошибка (MSE): Среднее квадратов ошибок между предсказанными и истинными значениями. Чем ниже значение MSE, тем лучше модель.
* Коэффициент детерминации ((R^2)): Измеряет, какую долю изменчивости зависимой переменной объясняют независимые переменные. Значение 1 означает идеальное предсказание, значение 0 означает, что модель не лучше предсказания средним значением.
* Средняя абсолютная ошибка (MAE): Среднее абсолютных разностей между предсказанными и реальными значениями. Даёт представление об ошибках в тех же единицах, что и сама переменная.

<a id="item-4"></a>
## 4. Расхождение Кульбака-Лейбмана (какая-то фигня)

Расхождение Кульбака-Лейблера (KL-расхождение) в контексте машинного обучения представляет собой меру, которая позволяет оценить, насколько одно вероятностное распределение отличается от другого. Этот метод получил широкое распространение в областях, связанных с теорией информации, статистикой и машинным обучением. Расхождение Кульбака-Лейблера не является симметричной мерой и также называется "расхождением информации".

### Определение
Для двух вероятностных распределений $P$ и $Q$ над одним и тем же пространством исходов $X$, KL-расхождение от $P$ до $Q$ определяется следующим образом:

$$ D_{KL}(P | Q) = \sum_{x \in X} P(x) \log\left(\frac{P(x)}{Q(x)}\right) $$

Для непрерывных распределений сумма заменяется на интеграл:

$$ D_{KL}(P | Q) = \int_{-\infty}^{+\infty} p(x) \log\left(\frac{p(x)}{q(x)}\right)dx $$

где $p(x)$ и $q(x)$ являются плотностями вероятности распределений $P$ и $Q$ соответственно.

### Свойства
* Неотрицательность: $D_{KL}(P | Q) \geq 0$ Расхождение равно нулю тогда и только тогда, когда $P$ и $Q$ совпадают почти везде.
* Несимметричность: $D_{KL}(P | Q) \neq D_{KL}(Q | P)$, что означает, что расхождение Кульбака-Лейблера от $P$ до $Q$ не то же самое, что от $Q$ до $P$.

### Интерпретация
KL-расхождение измеряет, сколько информации теряется при замене одного распределения другим. Этот показатель часто используется для оценки "расстояния" между распределениями в задачах машинного обучения, таких как аппроксимация или сжатие данных, а также в методах, основанных на максимизации правдоподобия.

### Применение в машинном обучении
* Методы оценки: В машинном обучении KL-расхождение используется в качестве функции потерь, особенно в задачах итеративной оптимизации параметров распределений.
* Обучение без учителя: Используется в алгоритмах сокращения размерности, таких как t-SNE, и в моделях с неполным обучением или обучением без учителя для вычисления расхождения между данными и модельными распределениями.

<a id="item-5"></a>
## 5. Критерии оптимизации 

В контексте машинного обучения, критерии оптимизации — это функции, которые должны быть минимизированы или максимизированы для достижения наилучшего возможного предсказательного качества модели. Эти критерии играют ключевую роль в процессе обучения модели, позволяя ей "учиться" на основе данных.

### Функция потерь (Loss Function)
Функция потерь измеряет, насколько предсказания модели отличаются от фактических значений. Целью обучения является минимизация этой функции, что соответствует увеличению точности модели. Существует множество функций потерь, и выбор зависит от типа задачи (регрессия, классификация и т.д.).

* Среднеквадратичная ошибка (MSE): широко используется для задач регрессии.
* Перекрёстная энтропия (Cross-entropy): часто применяется в задачах классификации.

### Функция стоимости (Cost Function)
Функция стоимости — это агрегированное представление потерь по всему набору данных. В контексте обучения с учителем, функция стоимости часто совпадает с функцией потерь, однако, она также может включать дополнительные термины, такие как регуляризация, для предотвращения переобучения.

Регуляризация (L1, L2): добавляется к функции стоимости для контроля сложности модели. L1-регуляризация (Лассо) определяется как сумма абсолютных значений коэффициентов модели, а L2-регуляризация (Ридж) — как сумма квадратов коэффициентов. Обе помогают предотвратить переобучение, "штрафуя" модели за слишком большие веса.

### Функция награды (Reward Function)
Используется преимущественно в обучении с подкреплением, где модель "учится" на основе награды, получаемой в результате её действий. Целью является максимизация общей награды.

<a id="item-6"></a>
## 6. Способы оптимизации функций (градиентный спуск)

Для нахождения оптимальных параметров модели, которые минимизируют функцию потерь или стоимости, используются различные алгоритмы оптимизации (но мы будем рассматривать только один, остальные - более усовершенствованные градиентные спуски).

<a id="item-7"></a>
### Сначала простыми словами и на примере:

Градиентный спуск — это как спуск с горы в темноте, имея только фонарик. Представь, что ты стоишь на вершине горы и твоя задача — спуститься в самую низкую точку долины, но темно, и ты видишь только небольшой круг от света фонарика. Ты не можешь увидеть всю долину сразу, чтобы выбрать лучший путь, поэтому ты решаешь двигаться шаг за шагом, выбирая направление, в котором земля уходит вниз больше всего.

В машинном обучении эта "гора" представляет собой функцию потерь, которую нужно минимизировать, или другими словами, задачу найти наилучшие параметры для модели, чтобы она работала как можно лучше. "Высота" в данной точке на "горе" показывает, насколько плохо в данный момент работает модель. Цель — спуститься к самой низкой точке, то есть найти параметры модели, при которых значение функции потерь будет минимальным (модель будет работать как можно лучше).

Фонарик в этой аналогии — это градиент функции потерь, который показывает направление крутейшего спуска из текущей точки. "Шагаем" мы, обновляя параметры модели в направлении, противоположном градиенту, потому что мы хотим идти вниз, а градиент указывает вверх, к повышению функции потерь.

#### Пример
Предположим, у нас есть набор данных с показаниями термометра за месяц и мы хотим предсказывать температуру на следующий день, используя простую линейную модель типа "температура завтра = вес × температура сегодня + смещение". Параметрами модели являются "вес" и "смещение".

Сначала мы инициализируем наши параметры "наугад" и считаем, насколько хорошо наша модель предсказывает температуру (это наша высокая точка на "горе"). Затем, используя градиентный спуск, постепенно адаптируем "вес" и "смещение" таким образом, чтобы наши предсказания становились всё ближе к реальным значениям (спускаемся ниже на "горе"). На каждом шаге мы проверяем градиент, чтобы узнать, в каком направлении нам следует корректировать наши параметры, чтобы сделать предсказание нашей модели ближе к действительности.

Градиентный спуск подскажет нам, как нужно изменить "вес" и "смещение", чтобы наша модель с каждым шагом становилась только точнее, пока мы не достигнем точки, где модель предсказывает температуру с наименьшим возможным отклонением от реальных значений.

<a id="item-8"></a>
### Теперь научно

Градиентный спуск — это оптимизационный алгоритм, используемый в машинном обучении для минимизации функции потерь, то есть для нахождения параметров модели, которые делают модель как можно более точной. Градиентный спуск основан на наблюдении, что если многомерная функция потерь $J(\theta)$ равномерно увеличивается или уменьшается в направлении градиента $\nabla_\theta J(\theta)$, то, двигаясь в противоположном градиенту направлении, можно приблизиться к минимуму функции.

Основное Уравнение
Основное уравнение градиентного спуска для обновления параметров модели представляется как:

$$ \theta := \theta - \eta \nabla_\theta J(\theta) $$

где:

* $\theta$ — параметры модели (например, веса),
* $\eta$ — скорость обучения, которая определяет размер шага на каждой итерации,
* $\nabla_\theta J(\theta)$ — градиент функции потерь по отношению к параметрам.
  
#### Типы Градиентного Спуска:
* #### Пакетный Градиентный Спуск
При пакетном градиентном спуске для обновления параметров $\theta$ используется весь обучающий набор данных. Это обеспечивает стабильный путь к минимуму, но может быть вычислительно дорогостоящим при больших объемах данных.

* #### Стохастический Градиентный Спуск (SGD)
Стохастический градиентный спуск обновляет параметры $\theta$ по одному примеру за раз. Это может привести к быстрым, но более неравномерным обновлениям, что иногда позволяет быстрее найти достаточно хорошее решение.

* #### Мини-пакетный Градиентный Спуск
Мини-пакетный градиентный спуск является компромиссом между пакетным и стохастическим подходами, обновляя $\theta$ не на основе всего набора данных, а используя мини-пакеты фиксированного размера. Это способствует более эффективному использованию вычислительных ресурсов и дает возможность использовать оптимизации из области матричных вычислений.

#### Проблемы градиентного спуска
* Локальные минимумы: Градиентный спуск может "застрять" в локальном минимуме, который не является глобальным минимумом функции потерь.
* Выбор скорости обучения: Не существует универсального способа выбрать оптимальную скорость обучения.
* Седловые точки: В высокоразмерных пространствах седловые точки (где градиент равен нулю, но это не минимум) могут создавать проблемы для градиентного спуска.

<a id="item-9"></a>
## 7. Функции активации 

Функции активации играют центральную роль в нейронных сетях и машинном обучении, поскольку они помогают решать задачи, которые нелинейны по своей природе. Эти функции применяются к входным сигналам нейронов, преобразуя их таким образом, чтобы определить, должен ли нейрон "активироваться" или нет. В основном, функции активации добавляют нелинейность в процесс обучения, что позволяет нейронным сетям обучаться на сложных и многоуровневых данных.

### Основные виды функций активации

#### Сигмоид (Sigmoid)
Сигмоидальная функция, выражение которой:

$$ \sigma(x) = \frac{1}{1 + e^{-x}} $$

Принимает любое значение и сжимает его в диапазоне от 0 до 1. Несмотря на то, что сигмоид исторически был популярен, его использование сейчас ограничено из-за таких проблем, как затухание градиентов.

#### Гиперболический тангенс (Tanh)
Функция гиперболического тангенса, выражение которой:

$$ tanh(x) = \frac{e^{x} - e^{-x}}{e^{x} + e^{-x}} $$

Аналогично сигмоиду сжимает значения, но в диапазоне от -1 до 1. Это улучшает центрирование данных, но функция все равно страдает от затухания градиентов на больших значениях $x$.

#### **!!! Rectified Linear Unit (ReLU) !!!**
Функция ReLU стала стандартом для большинства нейронных сетей из-за своей простоты и эффективности:

$$ ReLU(x) = max(0, x) $$

Если вход положительный, функция возвращает его без изменений; если отрицательный — возвращает ноль. ReLU помогает уменьшить вероятность возникновения затухания градиентов и значительно ускоряет обучение, хотя имеет проблему "умирающих нейронов" для отрицательных входов.

#### Линейная (Linear)
Линейная функция активации фактически не применяет никакого преобразования (кроме умножения на коэффициент), и ее выражение:

$$ Linear(x) = ax $$

Она используется, когда нам нужно получить значения на выходе, которые можно прямо сравнивать с целевыми значениями без ограничений по диапазону.

### Зачем нужны функции активации?
Функции активации позволяют нейронным сетям учить сложные и нелинейные взаимосвязи в данных. Без нелинейности, добавляемой этими функциями, нейронная сеть, независимо от количества слоев и нейронов, эквивалентна однослойной сети с линейными активациями, способной моделировать только линейные отношения.

<a id="item-10"></a>
## 8. Метрики качества в заданных классификациях 
В задачах классификации в машинном обучении важно не только настроить модель для предсказания классов объектов, но и уметь оценивать качество её работы. Существует несколько ключевых метрик, позволяющих объективно оценить эффективность классификатора.

### Матрица ошибок (Confusion Matrix)
Основой для расчета многих метрик служит матрица ошибок — таблица, которая позволяет визуализировать ошибки классификации модели, сравнивая истинные метки с предсказанными. Матрица состоит из четырех частей:

* True Positive (TP): модель правильно предсказала положительный класс.
* True Negative (TN): модель правильно предсказала отрицательный класс.
* False Positive (FP): модель неправильно предсказала положительный класс (ошибка первого рода).
* False Negative (FN): модель неправильно предсказала отрицательный класс (ошибка второго рода).

### Точность (Accuracy)
Точность показывает долю правильных предсказаний среди всех примеров и рассчитывается по формуле:

$$ Accuracy = \frac{TP + TN}{TP + TN + FP + FN} $$

Хотя точность является наиболее интуитивно понятной метрикой, она может быть вводящей в заблуждение в случае несбалансированных классов.

### Точность (Precision)
Точность показывает, какая часть объектов, отнесенных к положительному классу, действительно является положительным, и рассчитывается по формуле:

$$ Precision = \frac{TP}{TP + FP} $$

### Полнота (Recall)
Полнота показывает, какая часть объектов положительного класса была обнаружена классификатором, и рассчитывается по формуле:

$$ Recall = \frac{TP}{TP + FN} $$

### F-мера (F1-score)
F-мера — гармоническое среднее точности и полноты, позволяющее учитывать баланс между ними:

$$ F1 = 2 \times \frac{Precision \times Recall}{Precision + Recall} $$

Эта метрика полезна в ситуациях, когда нужно учесть одновременно и точность, и полноту, особенно при несбалансированных классах.
